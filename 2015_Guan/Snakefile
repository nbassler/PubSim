import fnmatch
import logging
import os
import subprocess
from pathlib import Path

from pymchelper.input_output import frompattern
from pymchelper.utils.mcscripter import Config, Template, Generator
from snakemake.io import expand, glob_wildcards

import collect
import merge
import plot

try:
    workspace = 'workspace_' + os.getenv('TIMEPATTERN')
except TypeError:
    workspace = 'workspace'

# wildcard with pattern for mcpartools configuration files
mcpartools_config_wildcard = "sim-files/config_{ion}.cfg"

def expected_collect_output_files(pmma_samples = -1):
    """
    Each Monte-Carlo simulation for PMMA+Ion combination may generate multiple BDO files (due to parallelization).
    These files are collected into single *.dat file by collect script.
    :parameter pmma_samples: number of PMMA samples to include for each ion (-1 for all of them)
    :return: list of files which are output of collect script
    """
    expected_files = []
    # inspect filesystem looking for files which match pattern and extract {ion} part
    ions, = glob_wildcards(mcpartools_config_wildcard)

    # read optional pattern from env. variable INPUT_FILTER, if not available assume a pattern which passes all
    input_filter = os.getenv('INPUT_FILTER', default='*')

    # calculate a subset of configuration using a wildcard pattern
    filtered_ions =  fnmatch.filter(ions, input_filter)
    for ion in filtered_ions:

        base_cwd = os.getcwd()  # this is needed first
        cfg = Config(mcpartools_config_wildcard.format(ion=ion))  # this one calls os.chdir to change working directory
        pmma_list = cfg.table_dict['PMMA']
        if pmma_samples >= 0:
            pmma_list = cfg.table_dict['PMMA'][:pmma_samples//2] + cfg.table_dict['PMMA'][-pmma_samples//2:]
        for pmma in pmma_list:
            expected_output_file = os.path.join(workspace, ion, "{ion}_{pmma}".format(ion=ion, pmma=pmma), 'bin_data_all.dat')
            expected_files.append(expected_output_file)
        os.chdir(base_cwd)  # let us change back working directory to the original one
    return expected_files

rule all:
    input:
        expected_files = expected_collect_output_files(int(config.get("pmma_samples", -1)))
    output:
        expand("{workspace}/summary.csv", workspace=workspace),
        expand("{workspace}/summary.svg", workspace=workspace),
        expand("{workspace}/summary.pdf", workspace=workspace),
        expand("{workspace}/metadata.json", workspace=workspace),
    benchmark:
        os.path.join(workspace, "benchmark_all.txt")
    run:
        # merge file generated by collect script into single data file which can be read by pandas library
        merge.merge_output_files(workspace,'bin_data_all.dat', output[0])

        # make plots from output CSV file
        plot.plot_results(output[0], output[1])
        plot.plot_results(output[0], output[2])

        # merge metadata files
        merge.merge_metadata_files(workspace,'metadata.json', output[3])


rule run_mc_simulation:
    input:
        "{workspace}/{ion}/{ion}.touch"
    output:
        "{workspace}/{ion}/{ion}_{pmma}/bin_data_all.dat",
        "{workspace}/{ion}/{ion}_{pmma}/metadata.json"
    benchmark:
        "{workspace}/{ion}/{ion}_{pmma}/benchmark.txt"
    run:
        f = os.path.join(output[0])
        Path(f).touch()
        print("Touching {}".format(f))

        new_dir = os.path.join(wildcards.workspace, wildcards.ion, wildcards.ion + "_" + wildcards.pmma)
        nprim = str(config.get("nprim", 1000))
        stop_time = str(config.get("stop_time", "00:02:00"))
        if "SLURM_JOB_NAME" in os.environ and os.getenv("SLURM_JOB_NAME") == 'run_mc_simulation':
            with open(os.path.join(new_dir, "jobs.cfg"), "w") as job_spec:
                job_spec.write("0-{ntasks} shieldhit -s --seedoffset=%t --time={stop_time} --nstat={nprim} .\n".format(ntasks=int(os.getenv("SLURM_NTASKS")) - 1, nprim=nprim, stop_time=stop_time))
            cmd = ["srun", "--multi-prog", "jobs.cfg"]
        else:
            cmd = ["shieldhit", "-s", "-n", nprim, "-t", stop_time, "."]
        subprocess.run(cmd, cwd=new_dir)

        # collect output from each simulation
        # read all bdo files and generate single file with summary
        estimators = frompattern(new_dir + '/*.bdo')
        if len(estimators) == 1:
            collect.save_summary_file(estimators[0], new_dir, output_suffix='_all.dat')
            collect.save_metadata_file(estimators[0], output[1])

rule generate_mc_input:
    input:
        "{workspace}/workspace.touch",
        mcpartools_config_wildcard
    output:
        "{workspace}/{ion}/{ion}.touch"
    benchmark:
        "{workspace}/{ion}/benchmark.txt"
    run:
        logging.basicConfig(level=logging.INFO)
        base_cwd = os.getcwd() # this is needed first
        cfg = Config(input[1])  # this one calls os.chdir to change working directory to something evil
        cfg.const_dict["WDIR"] = os.path.join(base_cwd, wildcards.workspace, wildcards.ion, "${NAME}")
        t = Template(cfg)
        Generator(t, cfg)
        os.chdir(base_cwd)  # let us change back working directory to the original one

        f = os.path.join(base_cwd, wildcards.workspace, wildcards.ion, wildcards.ion + '.touch')
        Path(f).touch()
        print("Touching {}".format(f))


rule prepare_workspace:
    output:
        "{workspace}/workspace.touch"
    benchmark:
        "{workspace}/benchmark_prepare.txt"
    run:
        os.makedirs(workspace,exist_ok=True)
        f = os.path.join(output[0])
        Path(f).touch()
        print("Touching {}".format(f))